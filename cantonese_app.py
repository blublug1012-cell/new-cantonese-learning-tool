import streamlit as st
import whisper
import os
import tempfile
import requests
import pandas as pd
import numpy as np
import time
from deep_translator import GoogleTranslator

# --- MoviePy 2.0+ å¯¼å…¥æ–¹å¼ ---
from moviepy import VideoFileClip, CompositeVideoClip, ColorClip, VideoClip
from PIL import Image, ImageDraw, ImageFont

# --- å­—ä½“ä¸‹è½½ ---
@st.cache_resource
def load_fonts():
    font_path = "NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
        with st.spinner("æ­£åœ¨ä¸‹è½½ä¸­æ–‡å­—ä½“æ”¯æŒ..."):
            try:
                r = requests.get(url, timeout=60)
                with open(font_path, "wb") as f:
                    f.write(r.content)
            except:
                st.error("å­—ä½“ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")
    return font_path

st.set_page_config(page_title="ç²¤è¯­è§†é¢‘å·¥åŠ Pro", layout="wide", page_icon="ğŸ¬")
st.title("ğŸ¬ ç²¤è¯­è§†é¢‘å·¥åŠ Pro (æ™ºèƒ½äº¤äº’ç‰ˆ)")

# --- è¾…åŠ©å‡½æ•° ---
@st.cache_resource
def load_model():
    return whisper.load_model("base")

def get_jyutping_list(text):
    from ToJyutping import get_jyutping_list
    return get_jyutping_list(text)

def safe_translate(text):
    try:
        # é¿å…é¢‘ç¹è¯·æ±‚
        time.sleep(0.1)
        res = GoogleTranslator(source='zh-TW', target='en').translate(text)
        if res and res != text:
            return res
    except:
        pass
    return "[Translation Error]"

# --- æ™ºèƒ½æ¢è¡Œç»˜åˆ¶å‡½æ•° ---
def draw_text_wrapper(draw, text, font, max_width, start_y, color, line_spacing=10):
    if not text: return start_y
    lines = []
    if ' ' in text:
        words = text.split(' ')
        current_line = []
        for word in words:
            test_line = ' '.join(current_line + [word])
            try: w = draw.textlength(test_line, font=font)
            except AttributeError: w = draw.textsize(test_line, font=font)[0]
            if w <= max_width: current_line.append(word)
            else:
                if current_line: lines.append(' '.join(current_line)); current_line = [word]
                else: lines.append(word); current_line = []
        if current_line: lines.append(' '.join(current_line))
    else: lines = [text]

    current_y = start_y
    for line in lines:
        try: w = draw.textlength(line, font=font); h = font.size
        except AttributeError: w, h = draw.textsize(line, font=font)
        draw.text(((720 - w) / 2, current_y), line, font=font, fill=color)
        current_y += h + line_spacing
    return current_y

# --- ä¸»ç¨‹åºé€»è¾‘ ---
if 'subtitles_df' not in st.session_state:
    st.session_state.subtitles_df = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None

with st.sidebar:
    st.header("1. ä¸Šä¼ è§†é¢‘")
    uploaded_file = st.file_uploader("é™åˆ¶ 200MB ä»¥å†…", type=["mp4", "mov"])
    
    if uploaded_file:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_file.read())
        st.session_state.video_path = tfile.name
        st.video(st.session_state.video_path)
        
        if st.button("ğŸš€ å¼€å§‹è¯†åˆ«ä¸ç¿»è¯‘", type="primary"):
            model = load_model()
            with st.status("AI æ­£åœ¨å·¥ä½œä¸­...", expanded=True) as status:
                st.write("ğŸ“‚ æå–éŸ³é¢‘...")
                video = VideoFileClip(st.session_state.video_path)
                audio_path = "temp_audio.wav"
                try: video.audio.write_audiofile(audio_path, verbose=False, logger=None)
                except: video.audio.write_audiofile(audio_path)
                
                st.write("ğŸ§  è¯†åˆ«ç²¤è¯­...")
                result = model.transcribe(audio_path, language='Chinese')
                
                st.write("ğŸ“ ç”Ÿæˆåˆç¨¿...")
                data = []
                for seg in result['segments']:
                    txt = seg['text']
                    # åˆæ¬¡ç”Ÿæˆ
                    jp_list = get_jyutping_list(txt)
                    jp_str = " ".join([i[1] if i[1] else i[0] for i in jp_list])
                    eng = safe_translate(txt)
                    
                    data.append({
                        "start": round(seg['start'], 2),
                        "end": round(seg['end'], 2),
                        "text": txt,
                        "jyutping": jp_str,
                        "english": eng
                    })
                
                st.session_state.subtitles_df = pd.DataFrame(data)
                if os.path.exists(audio_path): os.remove(audio_path)
                status.update(label="âœ… åˆç¨¿å®Œæˆï¼è¯·åœ¨å³ä¾§æ ¡å¯¹ã€‚", state="complete", expanded=False)

# --- æ ¡å¯¹ä¸å¯¼å‡º ---
if st.session_state.subtitles_df is not None:
    st.divider()
    st.header("2. æ™ºèƒ½æ ¡å¯¹")
    
    col_tip, col_btn = st.columns([3, 1])
    with col_tip:
        st.info("ğŸ’¡ æ“ä½œæŠ€å·§ï¼šåªç®¡ä¿®æ”¹ã€Œç²¤è¯­æ±‰å­—ã€åˆ—ï¼Œæ”¹å®Œç‚¹å‡»å³è¾¹çš„åˆ·æ–°æŒ‰é’®ï¼Œè‹±æ–‡å’Œç²¤æ‹¼ä¼šè‡ªåŠ¨ä¿®æ­£ï¼")
    
    # å…è®¸ç”¨æˆ·ç¼–è¾‘
    edited_df = st.data_editor(st.session_state.subtitles_df, num_rows="dynamic", use_container_width=True, key="editor")

    # --- ğŸ†• æ–°å¢åŠŸèƒ½ï¼šä¸€é”®é‡æ–°ç¿»è¯‘ ---
    with col_btn:
        st.write("") # å ä½å¯¹é½
        if st.button("âœ¨ åˆ·æ–°ç¿»è¯‘ä¸ç²¤æ‹¼", type="primary"):
            with st.spinner("æ­£åœ¨æ ¹æ®æ‚¨çš„ä¿®æ”¹é‡æ–°ç”Ÿæˆ..."):
                updated_data = []
                # éå†ç”¨æˆ·ç¼–è¾‘åçš„è¡¨æ ¼
                for index, row in edited_df.iterrows():
                    new_text = row['text']
                    
                    # é‡æ–°ç”Ÿæˆç²¤æ‹¼ (å› ä¸ºæ±‰å­—å˜äº†ï¼Œå‘éŸ³è‚¯å®šå˜äº†)
                    jp_list = get_jyutping_list(new_text)
                    new_jp = " ".join([i[1] if i[1] else i[0] for i in jp_list])
                    
                    # é‡æ–°ç¿»è¯‘è‹±æ–‡ (å› ä¸ºæ±‰å­—å˜äº†ï¼Œæ„æ€è‚¯å®šå˜äº†)
                    new_eng = safe_translate(new_text)
                    
                    updated_data.append({
                        "start": row['start'],
                        "end": row['end'],
                        "text": new_text,       # ä½¿ç”¨ä¿®æ”¹åçš„æ±‰å­—
                        "jyutping": new_jp,     # æ–°ç²¤æ‹¼
                        "english": new_eng      # æ–°ç¿»è¯‘
                    })
                
                # æ›´æ–° Session State å¹¶å¼ºåˆ¶åˆ·æ–°ç•Œé¢
                st.session_state.subtitles_df = pd.DataFrame(updated_data)
                st.success("âœ… å·²æ ¹æ®ä¸­æ–‡æ›´æ–°æ‰€æœ‰ç¿»è¯‘ï¼")
                st.rerun()

    st.divider()
    st.header("3. è§†é¢‘åˆæˆ")
    
    if st.button("ğŸ¬ ç”Ÿæˆè§†é¢‘"):
        font_path = load_fonts()
        v_path = st.session_state.video_path
        # ä½¿ç”¨æœ€æ–°çš„æ•°æ®è¿›è¡Œåˆæˆ
        subs = st.session_state.subtitles_df.to_dict('records')
        
        progress = st.progress(0)
        status = st.empty()
        
        try:
            status.text("æ­£åœ¨åˆå§‹åŒ–...")
            W, H = 720, 960
            padding = 60
            max_text_width = W - (padding * 2)
            
            clip = VideoFileClip(v_path)
            try: clip = clip.resized(width=W)
            except AttributeError: clip = clip.resize(width=W)
            
            target_h = 500
            if clip.h > target_h:
                clip = clip.crop(y1=(clip.h - target_h)/2, height=target_h)
            
            def make_frame(t):
                img = Image.new('RGBA', (W, H), (0, 0, 0, 0))
                draw = ImageDraw.Draw(img)
                cur = next((s for s in subs if s['start'] <= t <= s['end']), None)
                nxt = next((s for s in subs if s['start'] > t), None)
                try:
                    f_cn = ImageFont.truetype(font_path, 55)
                    f_jp = ImageFont.truetype(font_path, 30)
                    f_en = ImageFont.truetype(font_path, 26)
                except:
                    f_cn = ImageFont.load_default(); f_jp = ImageFont.load_default(); f_en = ImageFont.load_default()
                
                cursor_y = target_h + 50
                if cur:
                    cursor_y = draw_text_wrapper(draw, cur['text'], f_cn, max_text_width, cursor_y, "#FFD700", 15)
                    cursor_y += 15 
                    cursor_y = draw_text_wrapper(draw, cur['jyutping'], f_jp, max_text_width, cursor_y, "#87CEEB", 10)
                    cursor_y += 15
                    cursor_y = draw_text_wrapper(draw, str(cur['english']), f_en, max_text_width, cursor_y, "#FFFFFF", 10)
                if nxt:
                    draw.text((50, 880), f"Next: {nxt['text']}", font=f_jp, fill="#555555")
                return np.array(img)

            status.text("æ­£åœ¨æ¸²æŸ“ (çº¦3åˆ†é’Ÿ)...")
            sub_clip = VideoClip(make_frame, duration=clip.duration)
            bg_clip = ColorClip(size=(W, H), color=(20, 20, 20), duration=clip.duration)
            final = CompositeVideoClip([bg_clip, clip.with_position(('center', 'top')), sub_clip.with_position('center')])
            
            out_file = "cantonese_final_v4.mp4"
            final.write_videofile(out_file, fps=24, codec='libx264', audio_codec='aac', logger=None)
            
            status.success("å®Œæˆï¼")
            progress.progress(100)
            with open(out_file, "rb") as f:
                st.download_button("â¬‡ï¸ ä¸‹è½½è§†é¢‘", f, file_name="cantonese_tutor_smart.mp4")
            st.video(out_file)
            
        except Exception as e:
            st.error(f"åˆæˆå‡ºé”™: {e}")
