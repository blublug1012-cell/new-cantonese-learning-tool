import streamlit as st
import whisper
import os
import tempfile
import requests
import pandas as pd
import numpy as np
import time
from deep_translator import GoogleTranslator

# --- MoviePy 2.0+ å¯¼å…¥æ–¹å¼ ---
from moviepy import VideoFileClip, CompositeVideoClip, ColorClip, VideoClip
from PIL import Image, ImageDraw, ImageFont

# --- å­—ä½“ä¸‹è½½ ---
@st.cache_resource
def load_fonts():
    font_path = "NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
        with st.spinner("æ­£åœ¨ä¸‹è½½ä¸­æ–‡å­—ä½“æ”¯æŒ..."):
            try:
                r = requests.get(url, timeout=60)
                with open(font_path, "wb") as f:
                    f.write(r.content)
            except:
                st.error("å­—ä½“ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")
    return font_path

st.set_page_config(page_title="ç²¤è¯­è§†é¢‘å·¥åŠ Pro", layout="wide", page_icon="ğŸ¬")
st.title("ğŸ¬ ç²¤è¯­è§†é¢‘å·¥åŠ Pro (æœ€ç»ˆå®Œç¾ç‰ˆ)")

# --- è¾…åŠ©å‡½æ•° ---
@st.cache_resource
def load_model():
    return whisper.load_model("base")

def get_jyutping_list(text):
    from ToJyutping import get_jyutping_list
    return get_jyutping_list(text)

def safe_translate(text):
    try:
        time.sleep(0.2)
        # å¼ºåˆ¶æŒ‡å®šç¹ä½“ä¸­æ–‡->è‹±æ–‡
        res = GoogleTranslator(source='zh-TW', target='en').translate(text)
        if res and res != text:
            return res
    except:
        pass
    return "[Translation Error]"

# --- ä¸»ç¨‹åºé€»è¾‘ ---
if 'subtitles_df' not in st.session_state:
    st.session_state.subtitles_df = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None

with st.sidebar:
    st.header("1. ä¸Šä¼ è§†é¢‘")
    uploaded_file = st.file_uploader("é™åˆ¶ 200MB ä»¥å†…", type=["mp4", "mov"])
    
    if uploaded_file:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_file.read())
        st.session_state.video_path = tfile.name
        st.video(st.session_state.video_path)
        
        if st.button("ğŸš€ å¼€å§‹è¯†åˆ«ä¸ç¿»è¯‘", type="primary"):
            model = load_model()
            
            with st.status("AI æ­£åœ¨æµæ°´çº¿å·¥ä½œä¸­...", expanded=True) as status:
                st.write("ğŸ“‚ æå–éŸ³é¢‘...")
                video = VideoFileClip(st.session_state.video_path)
                audio_path = "temp_audio.wav"
                
                # å…¼å®¹æ€§å¤„ç†
                try:
                    video.audio.write_audiofile(audio_path, verbose=False, logger=None)
                except:
                    video.audio.write_audiofile(audio_path)
                
                st.write("ğŸ§  è¯†åˆ«ç²¤è¯­...")
                result = model.transcribe(audio_path, language='Chinese')
                
                st.write("ğŸ“ ç”Ÿæˆæ•°æ®...")
                data = []
                for seg in result['segments']:
                    txt = seg['text']
                    jp_list = get_jyutping_list(txt)
                    jp_str = " ".join([i[1] if i[1] else i[0] for i in jp_list])
                    eng = safe_translate(txt)
                    
                    data.append({
                        "start": round(seg['start'], 2),
                        "end": round(seg['end'], 2),
                        "text": txt,
                        "jyutping": jp_str,
                        "english": eng
                    })
                
                st.session_state.subtitles_df = pd.DataFrame(data)
                
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                    
                status.update(label="âœ… å¤„ç†å®Œæˆï¼", state="complete", expanded=False)

# --- æ ¡å¯¹ä¸å¯¼å‡º ---
if st.session_state.subtitles_df is not None:
    st.divider()
    st.header("2. å­—å¹•æ ¡å¯¹")
    edited_df = st.data_editor(st.session_state.subtitles_df, num_rows="dynamic", use_container_width=True)
    
    if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹"):
        st.session_state.subtitles_df = edited_df
        st.success("å·²ä¿å­˜ï¼")

    st.divider()
    st.header("3. è§†é¢‘åˆæˆ")
    
    if st.button("ğŸ¬ ç”Ÿæˆè§†é¢‘"):
        font_path = load_fonts()
        v_path = st.session_state.video_path
        subs = st.session_state.subtitles_df.to_dict('records')
        
        progress = st.progress(0)
        status = st.empty()
        
        try:
            status.text("æ­£åœ¨åˆå§‹åŒ–...")
            W, H = 720, 960
            
            clip = VideoFileClip(v_path)
            
            # --- å…¼å®¹æ€§ä¿®æ”¹ï¼šresize ---
            try:
                clip = clip.resized(width=W) # v2.0 æ–°å†™æ³•
            except AttributeError:
                clip = clip.resize(width=W)  # æ—§å†™æ³•
            
            target_h = 500
            if clip.h > target_h:
                clip = clip.crop(y1=(clip.h - target_h)/2, height=target_h)
            
            def make_frame(t):
                img = Image.new('RGBA', (W, H), (0, 0, 0, 0))
                draw = ImageDraw.Draw(img)
                
                cur = next((s for s in subs if s['start'] <= t <= s['end']), None)
                nxt = next((s for s in subs if s['start'] > t), None)
                
                try:
                    f_cn = ImageFont.truetype(font_path, 50)
                    f_jp = ImageFont.truetype(font_path, 32)
                    f_en = ImageFont.truetype(font_path, 26)
                except:
                    f_cn = ImageFont.load_default()
                    f_jp = ImageFont.load_default()
                    f_en = ImageFont.load_default()
                
                y_start = target_h + 40
                
                if cur:
                    # è·å–æ–‡å­—å®½åº¦ (Pillow 10.0+ ä½¿ç”¨ textlength)
                    try:
                        w1 = draw.textlength(cur['text'], font=f_cn)
                        w2 = draw.textlength(cur['jyutping'], font=f_jp)
                        w3 = draw.textlength(str(cur['english']), font=f_en)
                    except AttributeError:
                        # æ—§ç‰ˆ Pillow å…¼å®¹
                        w1 = draw.textsize(cur['text'], font=f_cn)[0]
                        w2 = draw.textsize(cur['jyutping'], font=f_jp)[0]
                        w3 = draw.textsize(str(cur['english']), font=f_en)[0]

                    draw.text(((W-w1)/2, y_start), cur['text'], font=f_cn, fill="#FFD700")
                    draw.text(((W-w2)/2, y_start + 80), cur['jyutping'], font=f_jp, fill="#87CEEB")
                    draw.text(((W-w3)/2, y_start + 130), str(cur['english']), font=f_en, fill="#FFFFFF")

                if nxt:
                    draw.text((50, y_start + 220), f"Next: {nxt['text']}", font=f_jp, fill="#555555")
                    
                return np.array(img)

            status.text("æ­£åœ¨æ¸²æŸ“ (çº¦3åˆ†é’Ÿ)...")
            sub_clip = VideoClip(make_frame, duration=clip.duration)
            
            bg_clip = ColorClip(size=(W, H), color=(20, 20, 20), duration=clip.duration)
            
            # --- å…³é”®ä¿®æ”¹ï¼šset_position -> with_position ---
            final = CompositeVideoClip([
                bg_clip,
                clip.with_position(('center', 'top')),  # ä¿®å¤è¿™é‡Œ
                sub_clip.with_position('center')        # ä¿®å¤è¿™é‡Œ
            ])
            
            out_file = "cantonese_final.mp4"
            final.write_videofile(out_file, fps=24, codec='libx264', audio_codec='aac', logger=None)
            
            status.success("å®Œæˆï¼")
            progress.progress(100)
            
            with open(out_file, "rb") as f:
                st.download_button("â¬‡ï¸ ä¸‹è½½è§†é¢‘", f, file_name="cantonese_tutor.mp4")
            
            st.video(out_file)
            
        except Exception as e:
            st.error(f"åˆæˆå‡ºé”™: {e}")
            import traceback
            st.text(traceback.format_exc())
