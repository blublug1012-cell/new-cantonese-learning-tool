import streamlit as st
import whisper
import os
import tempfile
import requests
import pandas as pd
import numpy as np
import time
from deep_translator import GoogleTranslator
from ToJyutping import get_jyutping_list
# æ˜¾å¼å¯¼å…¥ moviepy çš„ç»„ä»¶
from moviepy.editor import VideoFileClip, CompositeVideoClip, ColorClip, VideoClip
from PIL import Image, ImageDraw, ImageFont

# --- å­—ä½“ä¸‹è½½ ---
@st.cache_resource
def load_fonts():
    font_path = "NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_path):
        url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
        with st.spinner("æ­£åœ¨ä¸‹è½½ä¸­æ–‡å­—ä½“æ”¯æŒ..."):
            try:
                r = requests.get(url, timeout=60)
                with open(font_path, "wb") as f:
                    f.write(r.content)
            except:
                st.error("å­—ä½“ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")
    return font_path

st.set_page_config(page_title="ç²¤è¯­è§†é¢‘å·¥åŠ Pro", layout="wide", page_icon="ğŸ¬")
st.title("ğŸ¬ ç²¤è¯­è§†é¢‘å·¥åŠ Pro (Python 3.9 ä¿®å¤ç‰ˆ)")

# --- ç¼“å­˜åŠ è½½ Whisper æ¨¡å‹ ---
@st.cache_resource
def load_model():
    return whisper.load_model("base")

# --- è¾…åŠ©ï¼šæ··åˆç¿»è¯‘å‡½æ•° ---
def safe_translate(text):
    # 1. å°è¯• Google
    try:
        time.sleep(0.3) # é˜²å°åœ
        # å¼ºåˆ¶æŒ‡å®šæºè¯­è¨€ä¸ºç¹ä½“ä¸­æ–‡(zh-TW)ï¼Œç›®æ ‡ä¸ºè‹±æ–‡(en)
        res = GoogleTranslator(source='zh-TW', target='en').translate(text)
        # å¦‚æœç¿»è¯‘ç»“æœä¸ä¸ºç©ºä¸”ä¸ç­‰äºåŸæ–‡
        if res and res != text:
            return res
    except:
        pass
    
    # 2. å¦‚æœå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨ï¼ˆä¸ç¿»è¯‘ï¼Œç›´æ¥æ˜¾ç¤ºé”™è¯¯æç¤ºï¼‰
    return "[Translation Error]"

# --- æ ¸å¿ƒé€»è¾‘ ---
if 'subtitles_df' not in st.session_state:
    st.session_state.subtitles_df = None
if 'video_path' not in st.session_state:
    st.session_state.video_path = None

with st.sidebar:
    st.header("1. ä¸Šä¼ è§†é¢‘")
    uploaded_file = st.file_uploader("é™åˆ¶ 200MB ä»¥å†…", type=["mp4", "mov"])
    
    if uploaded_file:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(uploaded_file.read())
        st.session_state.video_path = tfile.name
        st.video(st.session_state.video_path)
        
        if st.button("ğŸš€ å¼€å§‹è¯†åˆ«ä¸ç¿»è¯‘", type="primary"):
            model = load_model()
            
            with st.status("AI æ­£åœ¨æµæ°´çº¿å·¥ä½œä¸­...", expanded=True) as status:
                st.write("ğŸ“‚ æå–éŸ³é¢‘...")
                video = VideoFileClip(st.session_state.video_path)
                audio_path = "temp_audio.wav"
                video.audio.write_audiofile(audio_path, verbose=False, logger=None)
                
                st.write("ğŸ§  è¯†åˆ«ç²¤è¯­...")
                # æç¤º Whisper å®ƒæ˜¯ä¸­æ–‡
                result = model.transcribe(audio_path, language='Chinese')
                
                st.write("ğŸ“ ç”Ÿæˆç²¤æ‹¼ä¸ç¿»è¯‘...")
                data = []
                for seg in result['segments']:
                    txt = seg['text']
                    
                    # 1. ç²¤æ‹¼
                    jp_list = get_jyutping_list(txt)
                    jp_str = " ".join([i[1] if i[1] else i[0] for i in jp_list])
                    
                    # 2. ç¿»è¯‘
                    eng = safe_translate(txt)
                        
                    data.append({
                        "start": round(seg['start'], 2),
                        "end": round(seg['end'], 2),
                        "text": txt,
                        "jyutping": jp_str,
                        "english": eng
                    })
                
                st.session_state.subtitles_df = pd.DataFrame(data)
                
                if os.path.exists(audio_path):
                    os.remove(audio_path)
                    
                status.update(label="âœ… å¤„ç†å®Œæˆï¼", state="complete", expanded=False)

# --- æ ¡å¯¹ä¸å¯¼å‡º ---
if st.session_state.subtitles_df is not None:
    st.divider()
    st.header("2. å­—å¹•æ ¡å¯¹")
    st.info("ğŸ’¡ æç¤ºï¼šåŒå‡»ã€Œè‹±æ–‡ç¿»è¯‘ã€åˆ—å¯ç›´æ¥ä¿®æ”¹å†…å®¹ã€‚")
    
    edited_df = st.data_editor(
        st.session_state.subtitles_df,
        num_rows="dynamic",
        column_config={
            "start": "å¼€å§‹(s)",
            "end": "ç»“æŸ(s)",
            "text": "ç²¤è¯­æ±‰å­—",
            "jyutping": "ç²¤æ‹¼",
            "english": "è‹±æ–‡ç¿»è¯‘"
        },
        use_container_width=True
    )
    
    if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹"):
        st.session_state.subtitles_df = edited_df
        st.success("å·²ä¿å­˜ï¼")

    st.divider()
    st.header("3. è§†é¢‘åˆæˆ")
    
    if st.button("ğŸ¬ ç”Ÿæˆè§†é¢‘ (3:4 ç«–å±)"):
        font_path = load_fonts()
        v_path = st.session_state.video_path
        subs = st.session_state.subtitles_df.to_dict('records')
        
        progress = st.progress(0)
        status = st.empty()
        
        try:
            status.text("æ­£åœ¨åˆå§‹åŒ–...")
            W, H = 720, 960
            
            # è§†é¢‘å±‚
            clip = VideoFileClip(v_path)
            clip = clip.resize(width=W)
            
            target_h = 500
            if clip.h > target_h:
                clip = clip.crop(y1=(clip.h - target_h)/2, height=target_h)
            
            def make_frame(t):
                # é€æ˜èƒŒæ™¯
                img = Image.new('RGBA', (W, H), (0, 0, 0, 0))
                draw = ImageDraw.Draw(img)
                
                cur = next((s for s in subs if s['start'] <= t <= s['end']), None)
                nxt = next((s for s in subs if s['start'] > t), None)
                
                try:
                    f_cn = ImageFont.truetype(font_path, 50)
                    f_jp = ImageFont.truetype(font_path, 32)
                    f_en = ImageFont.truetype(font_path, 26)
                except:
                    f_cn = ImageFont.load_default()
                    f_jp = ImageFont.load_default()
                    f_en = ImageFont.load_default()
                
                y_start = target_h + 40
                
                if cur:
                    # æ±‰å­—
                    w1 = draw.textlength(cur['text'], font=f_cn)
                    draw.text(((W-w1)/2, y_start), cur['text'], font=f_cn, fill="#FFD700")
                    # ç²¤æ‹¼
                    w2 = draw.textlength(cur['jyutping'], font=f_jp)
                    draw.text(((W-w2)/2, y_start + 80), cur['jyutping'], font=f_jp, fill="#87CEEB")
                    # è‹±æ–‡
                    w3 = draw.textlength(str(cur['english']), font=f_en)
                    draw.text(((W-w3)/2, y_start + 130), str(cur['english']), font=f_en, fill="#FFFFFF")

                if nxt:
                    draw.text((50, y_start + 220), f"Next: {nxt['text']}", font=f_jp, fill="#555555")
                    
                return np.array(img)

            status.text("æ­£åœ¨æ¸²æŸ“ (è¯·è€å¿ƒç­‰å¾…ï¼Œçº¦2-3åˆ†é’Ÿ)...")
            sub_clip = VideoClip(make_frame, duration=clip.duration)
            
            final = CompositeVideoClip([
                ColorClip((W, H), color=(20, 20, 20), duration=clip.duration),
                clip.set_position(('center', 'top')),
                sub_clip.set_position('center')
            ])
            
            out_file = "cantonese_final.mp4"
            final.write_videofile(out_file, fps=24, codec='libx264', audio_codec='aac', logger=None)
            
            status.success("å®Œæˆï¼")
            progress.progress(100)
            
            with open(out_file, "rb") as f:
                st.download_button("â¬‡ï¸ ä¸‹è½½è§†é¢‘", f, file_name="cantonese_tutor.mp4")
            
            st.video(out_file)
            
        except Exception as e:
            st.error(f"åˆæˆå‡ºé”™: {e}")